# anahtar kelimeleri Ã§Ä±karan kÄ±sÄ±m
# KeyBERT metinde en sÄ±k tekrarlanan anlamlÄ±/anlamsÄ±z gruplarÄ± Ã§Ä±karÄ±r

import re
from .loader import get_kw_model


STOPWORDS = {
    "ve", "veya", "ama", "mi", "de", "da", "Ã§ok", "az", "ile",
    "bir", "bu", "ÅŸu", "o", "ben", "sen", "bana", "iÃ§in", "olan",
    "gibi", "daha", "her", "hiÃ§"
}


def extract_keywords(text: str, top_n: int = 7):
    """
    KeyBERT ile ham kelime gruplarÄ±nÄ± Ã§Ä±karÄ±r
    """
    kw_model = get_kw_model()  # ğŸ”¥ LAZY LOAD

    raw_keywords = kw_model.extract_keywords(
        text,
        keyphrase_ngram_range=(1, 2),
        stop_words=None,        # KeyBERT TÃ¼rkÃ§e stopword desteklemez
        top_n=top_n
    )

    return raw_keywords


def normalize_keywords(raw_keywords):
    """
    KeyBERT tarafÄ±ndan Ã¼retilen ham phrase'leri
    daha okunabilir ve anlamlÄ± anahtar kelimelere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
    """

    cleaned = []

    for kw, score in raw_keywords:

        # dÃ¼ÅŸÃ¼k skorlularÄ± ele
        if score < 0.35:
            continue

        kw = kw.lower()
        kw = re.sub(r"[^\w\s]", "", kw).strip()
        parts = kw.split()

        # tek kelime ama ekli/anlamsÄ±z
        if len(parts) == 1:
            if parts[0].endswith(("larÄ±", "leri", "masÄ±", "mesi")):
                continue

        # iki kelimeli bozuk n-gram'lar
        if len(parts) == 2:
            first, second = parts

            if first.endswith(("mesi", "masÄ±")):
                continue

            if second in STOPWORDS:
                continue

        cleaned.append(kw)

    # tekilleÅŸtirme
    cleaned = list(dict.fromkeys(cleaned))

    return cleaned[:7]


def get_keywords(text: str):
    raw = extract_keywords(text)
    return normalize_keywords(raw)


def keyword_statistics(text: str, keywords: list[str]):
    text = text.lower()
    stats = []

    for kw in keywords:
        count = text.count(kw.lower())
        if count == 0:
            continue

        stats.append({
            "keyword": kw,
            "value": count
        })

    return stats


def get_keywords_stats(text: str):
    raw = extract_keywords(text)
    final_keywords = normalize_keywords(raw)
    return keyword_statistics(text, final_keywords)
